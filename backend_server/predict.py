from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import torch
import torch.nn as nn
import numpy as np
from pydantic import BaseModel
import os
from typing import List

print("ğŸ§ âœ… [LOG] FastAPI ì„œë²„ ì‹¤í–‰ë¨ â€” í˜„ì¬ predict.py ìµœì‹  ë²„ì „!")

# ë‚˜ë¨¸ì§€ ê¸°ì¡´ ì½”ë“œ ì•„ë˜ ê·¸ëŒ€ë¡œ ìœ ì§€...


# âœ… ëª¨ë¸ êµ¬ì¡° ì •ì˜ (Fold1ê³¼ ì¼ì¹˜)
class CNNBiLSTMModel(nn.Module):
    def __init__(self, input_channels, input_time):
        super(CNNBiLSTMModel, self).__init__()
        self.input_channels = input_channels
        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=5, padding=2)
        self.bn1 = nn.BatchNorm1d(64)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool1d(2)
        self.lstm = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, bidirectional=True, batch_first=True)
        self.fc = nn.Linear(32 * 2, 1)

    def forward(self, x):
        if x.ndim == 4:
            x = x.squeeze(1)
        if x.shape[1] != self.input_channels:
            x = x.permute(0, 2, 1)  # [B, C, T] â†’ [B, T, C]
        x = self.pool(self.relu(self.bn1(self.conv1(x))))  # [B, 64, T']
        x = x.permute(0, 2, 1)  # [B, T', 64]
        lstm_out, _ = self.lstm(x)
        x = lstm_out[:, -1, :]  # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì¶œë ¥
        x = self.fc(x)
        return x

# âœ… ëª¨ë¸ ë¡œë“œ
model = CNNBiLSTMModel(input_channels=8, input_time=80)
current_dir = os.path.dirname(__file__)
model_path = os.path.join(current_dir, "saved_models/model_fold1_best.pt")

try:
    model.load_state_dict(torch.load(model_path, map_location="cpu"))
    model.eval()
    print("âœ… Fold 1 ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

# âœ… FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# âœ… CORS ì„¤ì • (Flutter ì—°ë™ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ì…ë ¥ ë°ì´í„° ì •ì˜
class EEGInput(BaseModel):
    data: List[List[float]]  # shape: [8][80]

# âœ… ì˜ˆì¸¡ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/predict")
async def predict(input_data: EEGInput):
    try:
        # 1. ì…ë ¥ ë°›ê¸°
        data = np.array(input_data.data)  # shape: (8, 80)
        print("ğŸ“¥ ì…ë ¥ shape:", data.shape)
        print("ğŸ“¥ ì…ë ¥ ì¼ë¶€:\n", data[:, :5])

        # âœ… ìŠ¤ì¼€ì¼ ë³´ì • (ê°€ì¥ ì¤‘ìš”!)
        data *= 1e4  # ì…ë ¥ê°’ì´ ë„ˆë¬´ ì‘ì„ ê²½ìš° ë³´ì •

        # 2. ì°¨ì› ë§ì¶° Tensor ë³€í™˜
        if data.shape != (8, 80):
            return {"error": f"Invalid shape: {data.shape}, expected (8, 80)"}
        tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)  # [1, 8, 80]
        print("ğŸ§  ëª¨ë¸ ì…ë ¥ shape:", tensor.shape)

        # 3. ì¶”ë¡ 
        output = model(tensor)
        print("âš™ï¸ ëª¨ë¸ ì›ì‹œ ì¶œë ¥ê°’:", output.item())

        prob = torch.sigmoid(output).item()
        print(f"ğŸ“ˆ ì˜ˆì¸¡ í™•ë¥  (sigmoid): {prob:.4f}")

        return {"probability": prob}

    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    print("ğŸ§ª ëª¨ë¸ ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    dummy = np.random.randn(8, 80).astype(np.float32)
    dummy *= 1e4  # scale ë§ì¶”ê¸°
    tensor = torch.tensor(dummy).unsqueeze(0)
    output = model(tensor)
    prob = torch.sigmoid(output).item()
    print(f"ğŸ§ª ìˆ˜ë™ ì˜ˆì¸¡ í™•ë¥ : {prob:.4f}")
